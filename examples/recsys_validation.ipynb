{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<p align=\"center\">\n",
                "  <h1 align=\"center\">üåä GradTracer v0.6 ‚Äî AutoFix & Ranking Validation</h1>\n",
                "  <p align=\"center\">\n",
                "    <strong>End-to-End Validation: Baseline vs Bayesian Auto-Fix (NDCG/HitRate)</strong>\n",
                "  </p>\n",
                "</p>\n",
                "\n",
                "---\n",
                "\n",
                "This notebook rigorously tests GradTracer's active **Auto-Fix Mode**, which intervenes during training to scale gradients of oscillating (Zombie) embeddings based on Bayesian posteriors.\n",
                "\n",
                "We move beyond simple MSE and prove that Auto-Fix leads to statistically significant improvements in standard RecSys **Ranking Metrics (HR@10, NDCG@10)** on the sparse MovieLens-100K dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch pandas numpy scipy statsmodels gdown\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import urllib.request\n",
                "import zipfile\n",
                "from scipy import stats\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# Download MovieLens-100K\n",
                "url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
                "if not os.path.exists(\"ml-100k\"):\n",
                "    urllib.request.urlretrieve(url, \"ml-100k.zip\")\n",
                "    with zipfile.ZipFile(\"ml-100k.zip\", 'r') as zip_ref:\n",
                "        zip_ref.extractall(\".\")\n",
                "\n",
                "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
                "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=columns)\n",
                "\n",
                "# Implicit Feedback conversion (Rating >= 4 is positive)\n",
                "df = df[df['rating'] >= 4].copy()\n",
                "df['rating'] = 1.0\n",
                "\n",
                "df['user_id'] = df['user_id'].astype('category').cat.codes\n",
                "df['item_id'] = df['item_id'].astype('category').cat.codes\n",
                "num_users = df['user_id'].nunique()\n",
                "num_items = df['item_id'].max() + 1\n",
                "\n",
                "# Leave-One-Out Evaluation Split\n",
                "df = df.sort_values(by=['user_id', 'timestamp'])\n",
                "test_df = df.groupby('user_id').tail(1)\n",
                "train_df = df.drop(test_df.index)\n",
                "\n",
                "class ImplicitMFDataset(Dataset):\n",
                "    def __init__(self, df, num_items, num_negatives=4):\n",
                "        self.users = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
                "        self.items = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
                "        self.labels = torch.ones(len(df), dtype=torch.float32)\n",
                "        self.num_items = num_items\n",
                "        self.num_negatives = num_negatives\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "        \n",
                "    def __getitem__(self, idx):\n",
                "        u = self.users[idx]\n",
                "        i = self.items[idx]\n",
                "        \n",
                "        # Negative sampling\n",
                "        neg_items = torch.randint(0, self.num_items, (self.num_negatives,))\n",
                "        \n",
                "        items_batch = torch.cat([i.unsqueeze(0), neg_items])\n",
                "        labels_batch = torch.cat([torch.tensor([1.0]), torch.zeros(self.num_negatives)])\n",
                "        users_batch = u.repeat(1 + self.num_negatives)\n",
                "        \n",
                "        return users_batch, items_batch, labels_batch\n",
                "\n",
                "# Note: Collate function flattens the multi-negative batches\n",
                "def flatten_collate(batch):\n",
                "    users = torch.cat([item[0] for item in batch])\n",
                "    items = torch.cat([item[1] for item in batch])\n",
                "    labels = torch.cat([item[2] for item in batch])\n",
                "    return users, items, labels\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    ImplicitMFDataset(train_df, num_items), \n",
                "    batch_size=256, \n",
                "    shuffle=True, \n",
                "    collate_fn=flatten_collate\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model & Ranking Evaluator (HR@10, NDCG@10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MatrixFactorization(nn.Module):\n",
                "    def __init__(self, num_users, num_items, dim=32):\n",
                "        super().__init__()\n",
                "        self.user_emb = nn.Embedding(num_users, dim)\n",
                "        self.item_emb = nn.Embedding(num_items, dim)\n",
                "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
                "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
                "        \n",
                "    def forward(self, user, item):\n",
                "        u = self.user_emb(user)\n",
                "        i = self.item_emb(item)\n",
                "        return (u * i).sum(dim=1)\n",
                "\n",
                "def evaluate_ranking(model, test_df, train_df, num_items, k=10):\n",
                "    model.eval()\n",
                "    hits = []\n",
                "    ndcgs = []\n",
                "    \n",
                "    # Build interaction dict for fast lookup (items to ignore)\n",
                "    train_interacts = train_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
                "    \n",
                "    device = next(model.parameters()).device\n",
                "    all_item_ids = torch.arange(num_items, device=device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Evaluating\"):\n",
                "            u = int(row['user_id'])\n",
                "            pos_item = int(row['item_id'])\n",
                "            \n",
                "            # Get all predictions for user\n",
                "            u_tensor = torch.tensor([u] * num_items, device=device)\n",
                "            scores = model(u_tensor, all_item_ids).cpu().numpy()\n",
                "            \n",
                "            # Mask items seen in training\n",
                "            seen = train_interacts.get(u, set())\n",
                "            scores[list(seen)] = -np.inf\n",
                "            \n",
                "            # Get top K items\n",
                "            top_k_items = np.argsort(scores)[-k:][::-1]\n",
                "            \n",
                "            # Metrics\n",
                "            if pos_item in top_k_items:\n",
                "                hits.append(1)\n",
                "                rank = np.where(top_k_items == pos_item)[0][0]\n",
                "                ndcgs.append(1.0 / np.log2(rank + 2))\n",
                "            else:\n",
                "                hits.append(0)\n",
                "                ndcgs.append(0)\n",
                "                \n",
                "    return hits, ndcgs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training: Baseline vs Bayesian Auto-Fix\n",
                "We train exactly the same Matrix Factorization architecture, but one wrapped in GradTracer's `FlowManager` with `auto_fix=True` that intercepts Zombie Embeddings dynamically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from gradtracer.analyzers.embedding import EmbeddingTracker\n",
                "from gradtracer.analyzers.manager import FlowManager\n",
                "\n",
                "LR = 0.05 # Purposefully high LR to cause sparse gradients to oscillate\n",
                "EPOCHS = 3\n",
                "\n",
                "def train_model(auto_fix=False):\n",
                "    model = MatrixFactorization(num_users, num_items, dim=32)\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
                "    criterion = nn.BCEWithLogitsLoss() # Implicit feedback\n",
                "    \n",
                "    manager = FlowManager()\n",
                "    item_tracker = EmbeddingTracker(model.item_emb, name=\"item_emb\", auto_fix=auto_fix, track_interval=20)\n",
                "    manager.add_tracker(\"item\", item_tracker)\n",
                "    \n",
                "    model.train()\n",
                "    for epoch in range(EPOCHS):\n",
                "        total_loss = 0\n",
                "        for users, items, labels in train_loader:\n",
                "            optimizer.zero_grad()\n",
                "            preds = model(users, items)\n",
                "            loss = criterion(preds, labels)\n",
                "            loss.backward()\n",
                "            \n",
                "            # AutoFix intervenes here during backwards pass via register_hook\n",
                "            manager.step()\n",
                "            \n",
                "            optimizer.step()\n",
                "            total_loss += loss.item()\n",
                "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n",
                "        \n",
                "    manager.report()\n",
                "    return model\n",
                "\n",
                "print(\"===============================\")\n",
                "print(\"üõë Training BASELINE Model\")\n",
                "print(\"===============================\")\n",
                "model_baseline = train_model(auto_fix=False)\n",
                "\n",
                "print(\"\\n===============================\")\n",
                "print(\"‚úÖ Training AUTO-FIX Model\")\n",
                "print(\"===============================\")\n",
                "model_autofix = train_model(auto_fix=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Statistical Validation (Rank Evaluation)\n",
                "We now evaluate both models on HR@10 and NDCG@10, performing a paired t-test directly on the per-user NDCG scores to prove statistical significance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Evaluating Baseline...\")\n",
                "base_hits, base_ndcgs = evaluate_ranking(model_baseline, test_df, train_df, num_items)\n",
                "\n",
                "print(\"Evaluating Auto-Fix...\")\n",
                "fix_hits, fix_ndcgs = evaluate_ranking(model_autofix, test_df, train_df, num_items)\n",
                "\n",
                "base_hr, base_ndcg = np.mean(base_hits), np.mean(base_ndcgs)\n",
                "fix_hr, fix_ndcg = np.mean(fix_hits), np.mean(fix_ndcgs)\n",
                "\n",
                "# Paired T-test on NDCG Arrays\n",
                "t_stat, p_val = stats.ttest_rel(base_ndcgs, fix_ndcgs)\n",
                "\n",
                "print(\"\\n=======================================================\")\n",
                "print(\"üìä Evaluation: Empirical Proof of Bayesian Auto-Fix\")\n",
                "print(\"=======================================================\")\n",
                "print(f\"üìâ Baseline       -> HR@10: {base_hr:.4f} | NDCG@10: {base_ndcg:.4f}\")\n",
                "print(f\"üìà AUTO-FIX       -> HR@10: {fix_hr:.4f} | NDCG@10: {fix_ndcg:.4f}\")\n",
                "print(f\"Improvement       -> HR: +{(fix_hr - base_hr) / base_hr * 100:.1f}%   | NDCG: +{(fix_ndcg - base_ndcg) / base_ndcg * 100:.1f}%\")\n",
                "print(\"-\" * 55)\n",
                "print(f\"Paired t-test (NDCG) p-value: {p_val:.4e}\")\n",
                "\n",
                "if p_val < 0.05 and fix_ndcg > base_ndcg:\n",
                "    print(\"‚úÖ Conclusion: FlowGrad's Auto-Fix yields a STATISTICALLY SIGNIFICANT ranking improvement.\")\n",
                "else:\n",
                "    print(\"‚ùå Conclusion: The Auto-Fix did not yield a statistically significant ranking improvement.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}