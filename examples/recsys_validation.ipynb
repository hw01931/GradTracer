{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<p align=\"center\">\n",
                "  <h1 align=\"center\">ðŸŒŠ FlowGrad v0.5 â€” RecSys Embedding Diagnostics</h1>\n",
                "  <p align=\"center\">\n",
                "    <strong>End-to-End Validation: Baseline â†’ Diagnose â†’ Fix â†’ Compare â†’ Statistical Proof</strong>\n",
                "  </p>\n",
                "</p>\n",
                "\n",
                "---\n",
                "\n",
                "This notebook demonstrates how FlowGrad's new **EmbeddingTracker** diagnoses common recommendation system failures (Dead Embeddings, Zombie Oscillation, Popularity Bias) and provides actionable XML prescriptions that actually improve performance. We also prove the improvement via formal statistical testing (Paired t-test).\n",
                "\n",
                "**Dataset:** MovieLens-100K\n",
                "**Model:** Matrix Factorization (PyTorch)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch pandas numpy scipy statsmodels gdown"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import urllib.request\n",
                "import zipfile\n",
                "from scipy import stats\n",
                "\n",
                "# Download MovieLens-100K\n",
                "url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
                "if not os.path.exists(\"ml-100k\"):\n",
                "    urllib.request.urlretrieve(url, \"ml-100k.zip\")\n",
                "    with zipfile.ZipFile(\"ml-100k.zip\", 'r') as zip_ref:\n",
                "        zip_ref.extractall(\".\")\n",
                "\n",
                "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
                "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=columns)\n",
                "\n",
                "# Re-index starting from 0\n",
                "df['user_id'] = df['user_id'].astype('category').cat.codes\n",
                "df['item_id'] = df['item_id'].astype('category').cat.codes\n",
                "\n",
                "num_users = df['user_id'].nunique()\n",
                "num_items = df['item_id'].nunique()\n",
                "print(f\"Users: {num_users}, Items: {num_items}, Ratings: {len(df)}\")\n",
                "\n",
                "# Simple Train/Test Split (Leave-One-Out for evaluation)\n",
                "df = df.sort_values(by=['user_id', 'timestamp'])\n",
                "test_df = df.groupby('user_id').tail(1)\n",
                "train_df = df.drop(test_df.index)\n",
                "\n",
                "class MFDataset(Dataset):\n",
                "    def __init__(self, df):\n",
                "        self.users = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
                "        self.items = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
                "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "        \n",
                "    def __getitem__(self, idx):\n",
                "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
                "\n",
                "train_loader = DataLoader(MFDataset(train_df), batch_size=1024, shuffle=True)\n",
                "test_loader = DataLoader(MFDataset(test_df), batch_size=1024, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Baseline Model & FlowGrad Tracking\n",
                "We train a standard Matrix Factorization model. We attach `EmbeddingTracker` to the Item Embedding layer to see what happens under the hood during training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import EmbeddingTracker\n",
                "\n",
                "class MatrixFactorization(nn.Module):\n",
                "    def __init__(self, num_users, num_items, dim=32):\n",
                "        super().__init__()\n",
                "        self.user_emb = nn.Embedding(num_users, dim)\n",
                "        self.item_emb = nn.Embedding(num_items, dim)\n",
                "        \n",
                "        # Initialize purposefully bad to trigger diagnostics later if needed, \n",
                "        # or just standard normal.\n",
                "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
                "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
                "        \n",
                "    def forward(self, user, item):\n",
                "        u = self.user_emb(user)\n",
                "        i = self.item_emb(item)\n",
                "        return (u * i).sum(dim=1)\n",
                "\n",
                "model_baseline = MatrixFactorization(num_users, num_items, dim=32)\n",
                "optimizer = torch.optim.Adam(model_baseline.parameters(), lr=0.05) # Aggressive LR\n",
                "criterion = nn.MSELoss()\n",
                "\n",
                "# Attach FlowGrad!\n",
                "item_tracker = EmbeddingTracker(model_baseline.item_emb, name=\"baseline_item_emb\")\n",
                "\n",
                "print(\"Training Baseline Model...\")\n",
                "model_baseline.train()\n",
                "for epoch in range(5):  # Short training for demo\n",
                "    total_loss = 0\n",
                "    for users, items, ratings in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        preds = model_baseline(users, items)\n",
                "        loss = criterion(preds, ratings)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        # FlowGrad Step\n",
                "        item_tracker.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. FlowGrad Diagnosis\n",
                "Let's see what FlowGrad found wrong with our baseline training dynamics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Human readable report\n",
                "item_tracker.report()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import AgentExporter\n",
                "\n",
                "# What the AI Agent sees:\n",
                "xml_output = AgentExporter.export_embedding(item_tracker)\n",
                "print(xml_output)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Applying the Fix (Prescription)\n",
                "FlowGrad likely detected **ZOMBIE_EMBEDDINGS** (due to our aggressive LR=0.05 causing optimizer oscillation) and **POPULARITY_BIAS** (since MovieLens is heavily skewed). \n",
                "\n",
                "Let's apply the prescribed fix: **Lower LR** (or SparseAdam) and implement **Log-Q Correction** or simpler negative sampling. For this demo, we'll fix the learning rate and add a simple L2 regularization to control the oscillation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_fixed = MatrixFactorization(num_users, num_items, dim=32)\n",
                "\n",
                "# FIX 1: Reduced LR to stop Zombie Oscillation\n",
                "# FIX 2: Added weight_decay (regularization) to prevent exploding norms in popular items\n",
                "optimizer_fixed = torch.optim.Adam(model_fixed.parameters(), lr=0.005, weight_decay=1e-5)\n",
                "criterion = nn.MSELoss()\n",
                "\n",
                "item_tracker_fixed = EmbeddingTracker(model_fixed.item_emb, name=\"fixed_item_emb\")\n",
                "\n",
                "print(\"Training Fixed Model...\")\n",
                "model_fixed.train()\n",
                "for epoch in range(5):\n",
                "    total_loss = 0\n",
                "    for users, items, ratings in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        preds = model_fixed(users, items)\n",
                "        loss = criterion(preds, ratings)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        item_tracker_fixed.step()\n",
                "        total_loss += loss.item()\n",
                "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n",
                "    \n",
                "item_tracker_fixed.report()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Statistical Proof of Improvement ($\\%$ MSE Reduction and Paired t-test)\n",
                "To ensure FlowGrad isn't just delivering heuristics, we construct a Paired t-test over the absolute errors on the test set. If FlowGrad's recommendations are mathematically sound (e.g. they structurally reduce gradient oscillating variance $\\sigma^2_{t}$ for embeddings), we expect a **statistically significant reduction in prediction error**.\n",
                "\n",
                "$\\Delta = E[MSE_{baseline}] - E[MSE_{fixed}]$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_individual_errors(model, loader):\n",
                "    model.eval()\n",
                "    errors = []\n",
                "    with torch.no_grad():\n",
                "        for users, items, ratings in loader:\n",
                "            preds = model(users, items)\n",
                "            batch_errs = (preds - ratings)**2\n",
                "            errors.extend(batch_errs.cpu().numpy().tolist())\n",
                "    return np.array(errors)\n",
                "\n",
                "baseline_errors = get_individual_errors(model_baseline, test_loader)\n",
                "fixed_errors = get_individual_errors(model_fixed, test_loader)\n",
                "\n",
                "baseline_mse = baseline_errors.mean()\n",
                "fixed_mse = fixed_errors.mean()\n",
                "\n",
                "# Paired T-test\n",
                "t_stat, p_val = stats.ttest_rel(baseline_errors, fixed_errors)\n",
                "\n",
                "print(\"=\\\" * 50)\n",
                "print(\"ðŸ“Š Evaluation: Empirical Proof of RecSys Fixes\")\n",
                "print(\"=\\\" * 50)\n",
                "print(f\"ðŸ“‰ Baseline Test MSE: {baseline_mse:.4f}\")\n",
                "print(f\"ðŸ“ˆ FIXED Test MSE:    {fixed_mse:.4f}\")\n",
                "print(f\"Improvement:          {(baseline_mse - fixed_mse) / baseline_mse * 100:.2f}%\")\n",
                "print(\"-\" * 50)\n",
                "print(f\"Paired t-test p-value: {p_val:.4e}\")\n",
                "\n",
                "if p_val < 0.05 and fixed_mse < baseline_mse:\n",
                "    print(\"âœ… Conclusion: The FlowGrad recommended RecSys fixes yield a STATISTICALLY SIGNIFICANT improvement.\")\n",
                "else:\n",
                "    print(\"âŒ Conclusion: The fixes do not deliver a statistically significant improvement.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}